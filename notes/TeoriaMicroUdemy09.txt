					SECCION 22 BACK TO THE CLIENT

			VIDEO 470 A FRE MORE PAGES

Ya tenemos las rutas /auth/signin | signout | signup y el index.Crearemos /tickets/new para crear un ticket, /tickets/:ticketId para visitar ese ticket y /orders/:orderId para mostrar info sobre una order+payment.
REcuerda que en Next.js un param obligatorio se creaba con corchetes y su nombre como nombre de archivo(tickets[ticketid].js).
Recuerda también que para crear rutas en Next debe ser dentro del folder pages y subrutas como /tickets/xxx hay que crear ese subdirectorio(subdirectorio==subruta).

			VIDEO 471 QUICK REMINDER ON FETCHING DATA IN NEXT

En una app Next hay un AppComponent que es el padre de todos.Este componente no sólo es el padre de todos,sino que también los provee con sus props.Está en el archivo _app.js:

const _app = ({ Component, pageProps, currentUser }) => {

* Puedo ver que surte a todos de sus pageProps(de sus props) y que en él se renderiza cada componente.
  
  return (
    <div>
      <Header currentUser={ currentUser} /> 
      <Component {...pageProps} />
    </div>
  )
NOTA: Next por defecto va a llamar al getInitialProps del AppComponent si lo tiene implementado,como es nuestro caso,pero no va a llamar a ningun otro(como nuestro LandingPage.getInitialProps).Es a éstos a los que tengo que invocar yo manualmente
Fijate que siempre lo controla todo este AppComponent,es aqui donde declaramos que si un componente llama a getInitialProps le pasaremos el resultado como props

  // LLamada para el app.getInitialProps
    const client = buildClient(appContext.ctx)
    const { data } = await client.get('/api/users/currentuser');

    // llamada para el hijo
    let pageProps = {};
    if (appContext.Component.getInitialProps) {
      pageProps = await appContext.Component.getInitialProps(appContext.ctx);
    };

Y fijate como incluso el AppComponent también pregunra por el currentUser,no sólo el LandingPage.Y es por esto que veré dos peticiones GET para obtener el user.
Esto es un error que nos dejamos,pues no hace falta hacer dos peticiones.La haremos en el _app.js y se la pasaremos hacia abajo al LandingPageComponent.

				VIDEO 472 TWO QUICK FIXES

Realmente es muy sencillo corregir este error.En vez de hacer una segunda petición le paso por props el valor:

const AppComponent = ({ Component, pageProps, currentUser }) => {
  return (
    <div>
      <Header currentUser={currentUser} />
      <Component currentUser={currentUser} {...pageProps} />
    </div>
  );
};
* REcuerda que en un archivo de Next hay dos contextos.El anterior es para el frontend,y todo lo que esté afuera es para el backend.Asi que hago la petición aqui y le mando a todos los componentes el currentUser.
NOTA:fijate que conveniente es hacer peticiones en este punto alto de la aplicación(el punto más alto).

NOTA: en vez de tener que importar el helper y crear una nueva instancia de axios cada componente que quiera usar getInitialProps,puedo abastecer la instancia desde el padre de todos AppComponent:
  
// LLamada para el app.getInitialProps
  const client = buildClient(appContext.ctx);
  const { data } = await client.get("/api/users/currentuser");

// llamada para el hijo
  let pageProps = {};
  if (appContext.Component.getInitialProps) {
    pageProps = await appContext.Component.getInitialProps(
     appContext.ctx,client,data.currentuser)
 } <- la paso como segundo argumento del await appContext.Component.getInitialProps.NO solo eso sino que le paso también la respuesta(aqui si que tengo el user.id,el email y el token.Puedo pasar cuanto quiera desde el padre alias Jesucristo.

Cada componente lo pedirá asi,en orden:
LandingPage.getInitialProps = async (context,client,currentUser) => {
  return {};
};

			VIDEO 473 SCAFFOLDING A FORM

Creamos un simple form:
const NewTicket = () => {
  return (
    <div className="container">
      <h1>Create New Ticket</h1>
      <form>
        <div className="form-group">
          <label htmlFor="title">Title</label>
          <input type="text" className="form-control" id="title" placeholder="Enter title" />
        </div>
        <div className="form-group">
          <label htmlFor="price">Price</label>
          <input type="number" className="form-control" id="price" placeholder="Enter price" />
        </div>
        <button className="btn btn-primary">Create Ticket</button>
      </form>
    </div>
  );
};

export default NewTicket;

				VIDEO 474 SANITIZING PRICE INPUT

Cualquier currency mundial sólo funcionará con céntimos asi que hay que controlar si el usuario introduce 0.000004 por ejemplo.Redondearemos a dos decimales:

const onBlur = () => {
  const value = parseFloat(price);

  // si es un string
  if (isNaN(value)) {
    return;
  }

  setPrice(value.toFixed(2));
};
Nada que no pueda hacer toFixed.

					VIDEO 475 TICKET CREATION

Recordando nuestros endpoints tenemos que hacer una petición POST a /api/tickets.Dado que estamos en Next tenemos tres formas de hacer una petición.
En este caso getInitialProps no me vale pues es una petición posterior al primer renderizado de un componente.
NOTA:practicar sobre propiedades computadas.
REcuerda que es igual axios.get que axios[get] luego:
const doRequest = async (method,uri,options) => {
  return await axios[method](uri,options)

IMPORTANTE:fijate que el hook que hicimos realiza una petición y si lo deseo me devuelve la respuesta:

const useRequest = ({ url, method, body, onSuccess }) => {
    const [errors, setErrors] = useState(null);
    const doRequest = async () => {
        try {
            setErrors(null)
            const response = await axios[method](url, body);
            // si al llamar a este hook le paso una cuarta opcion ese argumento será funcion callback que resuelva en la response.data cuando quiera en ese componente.
            if (onSuccess) {
                onSuccess(response.data);
            }
            return response.data;

Fijate también que no es lo mismo useRequest({url,method,body,onSuccess}) que useRequest(url,method,body,onSuccess).El primero es SÓLO UN ARGUMENTO,el segundo cuatro.

const {doRequest, errors } = useRequest({
    url: '/api/tickets',
    method: 'post',
    body: {
        title,
        price
    },
    onSuccess: (data) => console.log(data)
});
Realmente con este hook es sencillísimo hacer peticiones de cualquier tipo,a cualquier endpoint y con cualquier payload,además de ver la respuesta y los errores formateados.Genial.

 const handleSubmit = (e) => {
    e.preventDefault();
    doRequest();
  };

  return (
    <div className="container">
      <h1>Create New Ticket</h1>
      <form onSubmit={handleSubmit}>

				VIDEO 476 LISTING ALL TICKETS

Cuando el usuario cree un ticket vamos a redireccionarlo al / donde se verán todos los tickets.Para redireccionar en Next y otras operaciones hay que usar su enrutador:

import Router from 'next/router';
* Simplemente uso el método push
onSuccess: () => Router.push("/"),

Para obtener todos los tickets hay que hacer una petición en el getInitialProps de ese componente.

  const ticketList = tickets.map(ticket => (
    <tr key={ticket.id}>
      <td>{ticket.title}</td>
      <td>{ticket.price}</td>
    </tr>
  ))
Simplemente es hacer la UI.

						VIDEO 477 LINKING TO WILDCARDS

Recuerda que cuando cree un file tipo [ticketId].js eso es un param obligatorio y me será proveido en el objeto context.De nuevo para usar un <anchor> en Next tengo que usar su componente Link.

* En el componente puedo hacer peticiones y pasarlas al mismo componentee
LandingPage.getInitialProps = async (context,client,currentUser) => {
  const response = await client.get('/api/tickets');
  return { 
    tickets: response.data <- fijate que retorno 'tickets'
  };

* Ahora saco de las props todo lo necesario.
const LandingPage = ({ currentUser,tickets }) => {

Además,como es un archivo wildcard voy a tener que usar 'href' + 'as' en el Link.Esto es asi,el primero es la ruta al archivo,el segundo son los argumentos:

import Link from 'next/link';

   <Link 
      href="/tickets/[ticketId]" 
      as={`/tickets/${ticket.id}`}>
      <a>View</a>
   </Link>

					VIDEO 478 CREATING AN ORDER

 Vamos a seguir trabajando en este [ticketId].js .Haremos una petición inicial para recuperar el ticket con el id que viene como .Fijate que en este componente el objeto context es fundamental para extraer el id de la url

TicketShow.getInitialProps = async (context,client) => {
  const { ticketId } = context.query;
  const ticket = await client.get(`/api/tickets/${ticketId}`);
  return { ticket: ticket.data };
}

Recuerda que el propósito de este componente aparte de visualizar el ticket es mostrar un botón 'Purchase' para comprar el ticket(lo cual crea una order).
 
  const { doRequest, errors } = useRequest({
    url: '/api/orders',
    method: 'post',
    body: {
      ticketId: ticket.id
      },
      onSuccess: (order) => console.log(order)
      });

  return (
    <div>
      <h1>{ticket.title}</h1>
      <h4>{ticket.price}</h4>
      {errors}
      <button 
        className="btn btn-primary"
        onClick={doRequest}
       >Purchase This Ticket
       </button>

Realmente con el hook y sabiendo como va Next es muy sencillo

				VIDEO 479 PROGRAMMATIC NAVIGATION TO WILDCARDS

Vamos a crear otro archivo wildcard para ver la Order.Fijate que para rescatarlo fue por el nombre entre [] + context.query( y que efectivamente son parámetros opcionales de la queryString).

Bien,recuerda que para poder navegar a este tipo de archivos antes tuve que usar href+as.Esta vez habrá que usar dos argumentos con la misma sintaxis,ya que vamos a usar el método estático Router.push:

  onSuccess: (order) => Router.push(
      "/orders/[orderId]", `/orders/${order.id}`),
Fijate que el primero es la ruta al archivo y el segundo la url a mostrar.
Asi es como se navega programáticamente en Next a files con wildcards.

				VIDEO 480 THE EXPIRATION TIMER

Lo primero es pedir la order rescatando de los argumentos de la queryString que vendrán.REcuerda params para los obligatorios y query para los opcionales.

OrderShow.getInitialProps = async (context,client) => {
  const { orderId } = context.query
  const { data } = await client.get(`/api/orders/${orderId}`)
  return { order: data }

* Habrá que calcular cada segundo el timer.

 const [timeLeft,setTimeLeft] = useState(0);

  useEffect(() => {
    const findTimeLeft = () => {
      const msLeft = new Date(order.expiresAt) - new Date();
      setTimeLeft(Math.round(msLeft / 1000));
    };
    // dado que el interval va a tardar un segundo tengo que llamar yo la primera vez a la función
    findTimeLeft();
    // para limpiar el intervalo hay que asignarlo
    const timerId = setInterval(findTimeLeft, 1000);
    return () => {
      clearInterval(timerId);
    };
  }, [order]);

					VIDEO 481 SHOWING THE STRIPE FORM

REcuerda que vamos a usar stripe para los pagos,y que me iban a devolver un token que tengo que enviar al backend.
Cuando el usuario complete su formulario me darán ese token en el front,y se manda al backend.Lógicamente hay que instalar su librería.
>npm i react-stripe-checkout

ahora me importo su HOC,el cual es un botón para pagar que abre su folder:
import StripeCheckout from 'react-stripe-checkout'.

Y lo añado en mi frontend.Me pedirán la publishable key(la key publica) y me devuelve el token en una callback en la propiedad token:
    <StripeCheckout
      token={(token) => console.log(token)}
      stripeKey="pk_test_.." />
Fijate que aunque sea una clave pública debería usar una variable de entorno.En Next cambia un poco(ya que alcanza servidor y navegador),lo que hay que hacer es crear un '.env.local' .Despues si antepongo NEXT_PUBLIC a la variable será para el browser y si no pongo nada es para el backend.Ejemplo:
SITE_URL=localhost <- para el backend
NEXT_PUBLIC_PAYMENT_TOKEN=xxx <-esta es expuesta en el browser.

  <StripeCheckout
      token={(token) => console.log(token)}
      stripeKey={process.env.NEXT_PUBLIC_STRIPE_KEY}
      amount={order.ticket.price*100}
      email={currentUser.email}
           />

Fijate que es imprescindible hoy en dia mandar el email del comprador
	
				VIDEO 485 TEST CREDIT CARD NUMBERS

Si voy a https://stripe.com/docs/testing veré la documentación sobre testing.
Hay muchos numeros de tarjeta.Parece que en todos puedo usar cualquier fecha futura para la caducidad y cualquier CVC de 3 digitos(4 para una American Express).
El más fácil de recordar es 4242424242...
Puedo ver que el objet literal que me devuelve la callback token tiene el token a mandar en su propiedad id.

				VIDEO 486 PAYING FOR AN ORDER

Volviendo al payments srv vemos que tenemos que hacer una petición a /api/payments donde se mirará por los campos token y orderId además de que sea un usuario autenticado.
En nuestro caso tenemos un problema,ya que sólo tenemos una oportunidad para mandar el id,vamos a tener que retocar nuestro hook useRequest para que la función doRequest admita argumentos opcionales y vayan para el body:

token={ ({id}) => doRequest({ token: id })}

Este argumento será un objeto,por si en un futuro escalara esta app:
    const doRequest = async (props={}) => {

        try {
            setErrors(null)
            const response = await axios[method](url,
                {...body, ...props});

Pero tan pronto como haga esto voy a tener un error en cada uno de estos:
onClick={doRequest} ya que con esta forma el primer argumento es pasado automaticamente a la funcion(y el argumento es el evento onClick).Lógicamente da fallo al querer meterlo en el body de la petición.

La solución es no usar la forma corta.
 onClick={() => doRequest()}>
De esta forma la función es invocada con 0 argumentos.Fijate que ambas zonas de paréntesis no tienen nada que ver una con otra.

					VIDEO 487 FILTERING RESERVED TICKETS

Fijate que cuando un ticket es pagado ya no está disponible,pero lo seguimos mostrando.Sería mejor filtrarlo,ya que no se puede pagar más veces(esta reservado).
Recuerda que es la existencia de la propiedad orderId la que dictamina si un ticket está siendo reservado.

Lo mejor es retocar el endpoint que devuelve los tickets y que ahora devuelve todos por:
const tickets = await Ticket.find({orderId:undefined});

						VIDEO 488 HEADER LINKS

Realmente nos faltan algunos links en la navbar.Es muy sencillo:
    currentUser && { 
          label:'Sell Tickets', href:'/tickets/new'  
        },
        currentUser && { 
          label:'My Orders', href:'/orders'  
        },
Sin embargo,nos falta el file para ver las orders de un user

					VIDEO 489 RENDERING A LIST OF ORDERS

Creamos pues ese file /pages/orders/index.js y lo que sea que ponga en ese componente será lo que se muestre en el GET a /orders 
Fijate que ya tenemos el endpoint bien,filtrando por el usuario actual:

   const orders = await Order.find({
        userId: req.currentUser!.id,
    }).populate('ticket');

Asi que el componente no puede ser más sencillo,ya que hará la petición en el getInitialProps:

const OrderIndex = ({ orders }) => {
  const orderList = orders.map((order) => (
    <tr key={order.id}>
      <td>{order.ticket.title}</td>
      <td>{order.status}</td>
      <td>
        <Link href="/orders/[orderId]" as={`/orders/${order.id}`}>
          <a>View Order</a>
        </Link>
      </td>
    </tr>
  ));

  return (
    <div className="container mt-4">
      <h1>My Orders</h1>
      <table className="table table-striped table-hover table-light">
        <thead>
          <tr>
            <th>Title</th>
            <th>Status</th>
            <th>Link</th>
          </tr>
        </thead>
        <tbody>{orderList}</tbody>
      </table>
    </div>

Es obvio que quedaría por hacer todo el frontend de la app.Pero como introducción a Kubernetes creo que ha cumplido de sobra su cometido.

					SECCION 23 CI/CD & DEPLOY

ESta sección va a ser muy divertida.Fijate que múltiples equipos de trabajo deben ser capaces de trabajar cada uno en un Servicio a la vez.
Además deberán ser capaces de mergear estos trabajos y hacer un redeploy sin tener conflictos ni errores.
Para controlar todo esto necesitaré entender el Workflow.Stephen me aconseja así:
* EN LOCAL
1- Hacer cambios al código en un determinado servicio
2- Hacer el commit a cualquier rama que no sea la master
3- Hacer el push de esa rama a Github
* EN GITHUB/REMOTO
1- Github recibe la rama actualizada
2- Manualmente creo una PR para mergear esta nueva rama en la master
3- Configuraremos Github para que corra todos los test en el proyecto tras recibir esta PR
4- Cuando pasen los test, mergearé la PR en la master
5- Configuraremos github para que automáticamente haga un build y redeploy a un live kubernetes cluster si la master cambia(que lo hace en el merge de la PR)

				VIDEO 491 GIT REPOSITORY APPROACHES

Normalmente hay dos acercamientos posibles para usar Git en un entorno de Microservices.
1º: usar un 'monoRepo'.Un único repo vigila por todos 
2ª: usar un 'repo per service'.Un repo por cada microservicio.

Aunque pueda parecer que la segunda opción es mejor,incluso grandes compañias usan la primera.Esto tiene su razón de ser,ya que cada vez que se crea un repositorio hay mucho trabajo por detrás.
Puedo que haya que crear keys,habrá que configurar los pipelines.Es un montón de trabajo extra innecesario.
Sin embargo usar un monoRepo también tiene sus downsides como veremos más adelante,aún asi,es la opción que tomaremos.

NOTA:fijate que sólo ignoró 'node_modules'.Es recursivo?
NOTA:usaremos GitHub para tener acceso a las GitHub Actions y asi ejecutar los test automáticamente.

Con todo esto en mente creo un repo local,stageo,commiteo y hago el push.

					VIDEO 492 GITHUB ACTIONS

Tenemos que configurar a GitHub para que realize los tests cada vez que reciba una PR?o que haga el merge de ella?.

NOTA: En GitHub,cada vez que se realiza una acción(como crear una PR,cerrar una PR,hacer un Fork,incluso hacer un simple Push,...) se crea un Event internamente en GitHub.
Cuando un evento ocurre puedo lanzar una acción(GitHubActions).Una GitHub Action es un pequeño script donde poner cualquier código(ejecutar comandos,run tests,deploys,...)
Vamos a crear una Action para cuando 'se cree una PR'.También nos aseguraremos que se ejecuta la misma action si se 'actualiza la PR'.Esta accion ejecutará todos los tests.
Si alguno falla se nos informará en la PR.

Sea como sea voy a la pestaña Actions y eligo crear la mía.Fijate que es un .yml
Lo renombramos a tests.yml(ya que va a ejecutar los tests).

Habrá que especificar cuando ejecutar la acción y qué comandos ejecutar:

#name es el nombre de este workflow
name: tests
# cuando disparar el job
on: 
  pull_request

#puedo crear varios jobs,cada uno con sus steps 
jobs: 
  build:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2<-prebuilt action que simplemente toma todo el código
      - run: cd auth && npm install && npm run test:ci <- ejecuta este comando

NOTA: no tenemos este comando test:ci en el package.json(solo tengo test y start en auth).Este comando hay que crearlo.Y hay que crearlo porque el npm run test se queda en --watch y queremos ejecutar sólo UNA vez el test y salir.

Guardo el archivo(usando start commit).En el siguiente video crearemos una PR y veremos que sucede.

NOTA. la imagen de Github que se usará ya tiene npm o yarn instalados,lógicamente

Es una sintaxis que iré aprendiendo.Fijate que puedo incluso especificar las ramas con barnches: [name1,name2,name3]:
on:
  # Triggers the workflow on push or pull request events but only for the master branch
  push:
    branches: [ master ]
  pull_request:
    branches: [ master ]

				VIDEO 493  ADDING A CI TEST

Asi pues voy al microservicio 'auth' y añado el nuevo script:
"test:ci":"jest"
IMPORTANTE:fijate que he creado un commit en el remoto,asi que hay que hacer fetch+merge(que es un pull)
>git pull origin master
>git add commit push ...

Fijate que hay varios posibles errores ya que tiene la gente

				VIDEO 494 RUNNING TEST ON PR CREATION

simplemente agrego un console.log en el microservicio.Recuerda que los PR son siempre en otra rama.
NOTA:puedo ignorar los archivos temporales de vim con *~ si terminan en virgulilla o con *.swp y *.swo(hay gente que dice que use *.sw* por si cambia el ultimo caracter)

Asi que hago algun cambio y despues creo una nueva rama(fijate que el orden es importante:
git checkout -b dev
git add y commit
git push origin newBranch

Ahora creo manualmente en GitHub el PR hacia master.Voy al repo y a PRs y debería ver xxx has pushed changes y el boton 'compare & pull request' pero si no lo veo la creo yo con new pull request.
Importante la rama base es master(compare es la mia)

Es hora de hacer la pull request.Esto disparará los test.Afortunadamente me pasan,pero puede haber muchos fallos(algunos tienen fallo de permisos de jest).
NOTA: fijate que si el repo es privado tendré que configurar la autenticación.
Una vez hayan pasado se podría aceptar el merge con la PR.Pero antes vamos a ver que sucede cuando falle.

					VIDEO 495 OUTPUT OF FAILING TESTS

Vamos a hacer que un test falle.Fijate que no tengo que crear otra PR.Dado que ya he creado una,los commits se irán agregando a esa PR
En un test cualquiera cambio el status de la respuesta.Ahora hago el add commit y push y veré como fallan los test.
NOTA:aunque la GitHub Action falle aún podría hacer el merge pull request pero lógicamente no es lo que querriamos hacer con un test fallando.
Simplemente reenviamos de nuevo la status code correcta.
En los próximos videos vamos a ver como ejecutar todos los tests de nuestro proyecto en paralelo(no sólo uno como ahora tenemos)

				VIDEO 496 RUNNING TESTS IN PARALLEL

Hay dos formas de agregar el resto de tests a la GitHub Action.Una es muy obvia y sería seguir contatenando steps:

jobs:
  build: 
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - run: cd auth && npm install && npm run test:ci
* Ahora sería otra run que me cambie a otro srv,etc...Sin embargo esto ejecutaría los test uno detrás de otro,en serie o secuencialmente.
No queremos esto,pues estaría varios minutos esperando.Puedo crear más workflows que también se ejecuten en cada pull_request(segunda forma).

Lo primero será cambiar el nombre de este workflow y del file,ya que se llama tests.yml:
name: tests-auth <- cambio el nombre del file a tests-auth.yml
on: ... 

Fijate que los microservicios con testing son auth,orders,tickets y payments:

# Voy creando todos los files.Fijate que son en plural 
name: tests-orders

# On determina cuando ejecutar el script
on:
  pull_request

# jobs determina que tareas realizar
jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - run: cd orders && npm install && npm run test:ci

NOTA: if a workflow stalles out I can cancell it clicking on details and then on 'cancel workflow'.Be sure workflow is stalled out for some minutes before cancelling.
En teoría ahora debería hacer el merge con el PR,y como la master cambiará,disparar otra acción(un redeploy).Sin embargo hay que configurar esto.

				VIDEO 498 SELECTIVE TEST EXECUTION

En teoría tenemos todos los servicios aislados,con lo que un cambio en 'auth' no debería romper nada en payments u orders,asi que,¿para qué ejecutar sus tests si estamos seguros que funcionan?
Podemos configurar esto haciendo un pequeño cambio a los test.yaml.
Fijate que tuve que pullear el master remoto para abrir los archivos en el IDE

Realmente es muy sencillo,solo tengo que pasar un argumento 'paths' al pull_request condicionando la ruta de los archivos que cambien(fijate que puedo pasar ramas)

on:
  pull_request:
    paths:
      - 'auth/**' <- solo si cambiar cualquier archivo dentro de auth/

Increible.Puedo pasarle archivos en concreto o ramas.Repito el proceso para los otros tres servicios con testing.

					VIDEO 499 DEPLOYMENT OPTIONS

En cuanto a Providers Stephen analiza 4.Tanto AWS como GCP cobran 10 centimos por hora por tener un control node en kubernetes(lo que dispara el precio a ~120$ al mes).Azure cobra unos 70$ y Digital Ocean es la mejor opcion.

I just want to share this link with you it gives you a free 100$ DO credit you can use for 60 days.

https://m.do.co/c/50b8bebb68f1

				VIDEO 500 CREATING A HOSTED CLUSTER

Stephen recomienda al menos tres nodos(master+2slaves??)Adicionalmente habrá que contratar un balanceador de carga.También hay que darle un nombre al cluster,etc.
En mi caso instalaré todo en Hetzner,en dos máquinas.Parece que cobran por el balanceador,asi que tomaré la oferta inicial y haré un primer deploy con Digital Ocean de dos meses.
NOTA:en cuanto cree el cluster me empezarán a cobrar.Debo asegurarme que lo termino antes de que se acabe la promoción.Asi pues doy en crear cluster,selecciono versión y región.Eligo 3 nodos(master+2 workers).Es buena idea renombrar el cluster a un nombre lógico en vez de un hash.
Más adelante crearemos una GitHub pipeline para hacer el deploy a este cluster.

			VIDEO 501 REMINDER ON KUBERNETES CONTEXT

Una vez tenga el cluster hay que conectar kubectl con ese cluster.Como recordatorio kubectl puede conectarse a cualquier cluster cambiandole el contexto.
Asi que vamos a crear un segundo contexto usando la Digital Ocean CLI(se llama doctl de digital ocean controller).
La doc está en este repo: https://github.com/digitalocean/doctl
PUedo usar snap o este oneliner:
curl -sL https://github.com/digitalocean/doctl/releases/download/v<version>/doctl-<version>-linux-amd64.tar.gz | tar -xzv
Version 1.67.0
IMPORTANTE:falta moverlo => sudo mv ~/doctl /usr/local/bin

NOTA:lo dejo en /home/oscar el ejecutable(no,debo moverlo)

Compruebo que tengo visión sobre doctl.Una vez me dé alguna salida debo autenticarme.Pero necesitaré un token.Puedo generar uno en el dashboard en la sección API:
En cuanto lo tenga ejecuto el comando y pego el tokenn
>doctl auth init

oscar@acer-linux:~$ doctl auth init
Please authenticate doctl for use with your DigitalOcean account. You can generate a token in the control panel at https://cloud.digitalocean.com/account/api/tokens

Enter your access token: 
Validating token... OK

NOTA: tmb vale doctl auth init --access-token <myToken> y para w10 usar choco:
choco install doctl para Mac brew install doctl

Una vez autenticado ya podemos instalar un nuevo contexto para conectar el cluster remoto con mi kubectl local.
NOTA:fijate que podría crear cuentas truchas en DO o GCP para la promocion inicial si quiero tener el cluster visible para posibles empleadores.Mirar si puedo solucionarlo atemporalemente con sólo el balanceador en Hetzner.

				VIDEO 502 REMINDER ON SWAPPING CONTEXTS

Comandos útiles:
Autenticarse:
doctl auth init

Get connection info for our new cluster
doctl kubernetes cluster kubeconfig save <cluster_name>(para ver el nombre del cluster en el dashboard)
NOTA:esto también fija el contexto

List all contexts:
kubectl config view
NOTA:lo que me interesa es ver el name de cada context para swapear

Use a diferent context:
kubectl config use-context <context_name>

Ver el contexto actual:
kubectl config current-context

Asi que creo el nuevo contexto.Esto es vital para poder ver los pods,services,deplys,...Cada vez que cree un cluster debo meter su contexto en el kubectl para poder cambiar a él.
NOTA:recuerda que el master necesita más máquina que un worker.

De nuevo,no vamos a deployar nada por nosotros mismos,entrando por CLI al cluster,usaremos el workflow de Git.

				VIDEO 503 THE DEPLOYMENT PLAN

Vamos a usar 7 workflows(files) diferentes.Cuando cambie algo en alguno de ellos  se construirá una nueva imagen,se pusheará a Docker Hub y se Updateará el deployment.
Lógicamente cada workflow corresponde a un microservicio o folder.Ver imagen.
La razón de separarlo en 7 workflows es que si sólo hay cambios en un microservicio no se toque nada de lo ya existente en los otros 6.De esta forma podría reescribir un microservicio entero en otro lenguaje sin afectar al resto.

NOTA:hay un workflow para la carpeta infra que siempre es ejecutado en cada cambio asi que minimo se ejecutarás dos workflows en cada cambio.

		VIDEO 504 BUILDING AN IMAGE IN A GITHUB ACTION

Voy a workflows y creo uno nuevo from scratch.Usaremos la sintaxis deploy-service.yaml.
IMPORTANTE es entender cuando se va a ejecutar este job,ya que cada vez que se haga el merge de un PR va a contar como un push:
on:
  push:
    branches:
      - master
    paths:
      - 'auth/**'

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - run: cd auth && docker build -t oscargm40/auth-ticketing-k8s .

NOTA: no hace falta el cd auth.Puedo sustituir el . por auth:
- run: docker build -t oscargm40/auth-ticketing-k8s auth

IMPORTANTE:recuerda que para pushear una imagen a Docker Hub tengo que estar loggeado y estoy en un ubuntu que no es mío,sin loggear.
Claro que no voy a pasar mi username y password en el comando,sino que voy a crear un Secret en el repositorio

NOTA:en Settings/Secrets en cada repositorio puedo guardar pares de clave-valor encriptados. Los llamaremos DOCKER_USERNAME y DOCKER_PASSWORD.Al crearlos tendré acceso desde el script.Sin embargo no se importan sólo desde los secrets(tengo que usar env manualmente e importarlos yo)

*Esto es un único comando,ojo
- run: docker login -u $DOCKER_USERNAME -p $DOCKER_PASSWORD
  env:
    DOCKER_USERNAME: ${{ secrets.DOCKER_USERNAME }}
    DOCKER_PASSWORD: ${{ secrets.DOCKER_PASSWORD }} 

NOTA: si tengo fallo puedo usar la stdin:
run:
 echo $DOCKERHUB_PASSWORD | docker login -u $DOCKERHUB_USERNAME --password-stdin
* Lógicamente,ya estaré autenticado asi que hago el push en otro run:
  -run: docker push oscargm40/auth-ticketing-k8s

En el siguiente video comprobaremos que realmente se haga el rebuild

				VIDEO 505 TESTING THE IMAGE BUILD

Para testear esto simplemente mergeo la PR que tengo.Recuerda que mergear dispara el push sobre la master,asi que cumplirá los requisitos y hará el build.
En mi caso no he tenido problemas pero puede haber problemas de permisos,etc.
Fijate que aún nos queda decirle al cluster que use esta última nueva imagen y a infra que ejecute de nuevo todos los yaml(yo diría que ya lo tengo bien con latest en cada image con lo que un rebuild la montará).

				VIDEO 506 RESTARTING THE DEPLOYMENT

Ahora tengo que acceder al cluster,y decirle al Deployment responsable de este Pod que use esta nueva imagen,pero,¿como accedo al cluster de DO?.
Fijate que estoy en un GitHub container(al usar las Github Actions).Lo que vamos a hacer es instalar doctl,autenticarnos con una API key(usando un secret tal como acabamos de hacer).Fetchearemos el context y se lo pasaremos a kubectl.
NOTA: kubectl viene preinstalado en un Github container

ASi que al file anterior(deploy-auth.yaml) le agrego al final:
  - uses: digitalocean/action-doct@v2
    with:
      token: ${{ secrets.DIGITALOCEAN_ACCESS_TOKEN }} <- recuerda los spaces

El token va a ser un secret que llamaremos DIGITALOCEAN_ACCESS_TOKEN,para generarlo voy al dashboard en API y lo genero(le llamaremos algo semántico también allí,como github_access_token)

De forma similar a como he hecho en mi consola vamos a usar doctl para coger el contexto y pasarselo al kubectl de ese ubuntu :
  - run: doctl kubernetes cluster kubeconfig save <clusterName>

* Recuerda que el comando coge el contexto y lo pone como el current-context también,luego ya estoy con el kubectl del Github container apuntando a mi cluster:
  - run: kubectl rollout restart deployment <deployName>

El nombre lo puedo ver en el yaml del infra folder:
apiVersion: apps/v1
kind: Deployment
metadata:
  name: auth-depl

En este caso es 'auth-depl'.Por último,hago el commit del file del workflow y sería genial testear ya esto,sin embargo aún no hemos configurado nada en el cluster,no estamos ejecutando nada.Nos falta aplicar el folder 'infra' con un segundo workflow.
Tongue tie phrase: trabalenguas

				VIDEO 507 APPLING KUBERNETES MANIFEST

Este segundo workflow va a tratar sobre aplicar todos esos config files del folder infra y aplicarlos en el cluster.Va a ser pretty straightforward y muy parecido al primero asi que copio y pego todo en un nuevo file que llamaremos deploy-manifests.yaml
NOTA:todos estos config files se les llama manifest.

* Realmente será bastante sencillo
name: deploy-manifest

on:
  push:
    branches: [ master ]
    paths: 
      - 'infra/**'

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - uses: digitalocean/action-doctl@v2
        with:
          token: ${{ secrets.DIGITALOCEAN_ACCESS_TOKEN }}
      - run: doctl kubernetes cluster kubeconfig save ticketing-cluster
      - run: kubectl apply -f infra/k8s

Realmente esto ha sido sencillo.Sin embargo,ahora tenemos un problema.Nuestro Ingress Controller está apuntando a ticketing.dev y este dominio sólo existe en mi Sistema Operativo.Recuerda que el dominio apunta a mi minikube:
192.168.49.2 posts.com ticketing.dev

Este dominio dependerá de si estoy en producción o desarrollo.En resumen,el ingress-srv.yaml que tenemos no nos sirve tal como está.
Hay un par de formas de arreglar esto.

				VIDEO 508 PROD VS DEV MANIFEST FILES

La primera solución es bastante sencilla.Para arreglar esto creo dos folders extra en infra llamados k8s-prod y k8s-dev(además del que tenemos).

1- En el original k8s voy a dejar todos los config files que sean iguales tanto para un entorno de producción como de desarrollo,es decir,que les dé igual donde está el cluster

2- En el k8s-dev voy a dejar sólo los config files que vaya a usar en un ambiente de desarrollo,esto es,en un cluster local.

3- En el k8s-prod irán los de sólo producción,lógicamente.

Asi pues,muevo el ingress-srv.yaml a k8s-dev y creo otro con el mismo nombre en prod también.De momento no tengo el dominio pero aqui irá ese dominio

DAdo que he cambiado ingress-srv.yaml de zona tengo que cambiar el archivo de configuración de skaffold pues hemos roto la app.Nada más sencillo:

apiVersion: skaffold/v2alpha3
kind: Config
deploy:
  kubectl:
    manifests: 
      - ./infra/k8s/*
      - ./infra/k8s-dev/* <- agregamos la nueva carpeta a manifests.

TAmbién tengo que cambiar el workflow deploy-manifests.yaml de forma similar:
- run: kubectl apply -f infra/k8s && kubectl apply -f infra/k8s-prod <- Stephen comenta que es posible que apply -f pueda usar varios directorios como argumentos,pero mejor duplicamos el comando

NOTA: recordar que el cluster necesitará la creación de un par de secrets manualmente.Además del dominio.

					VIDEO 509 MANUAL SECRET CREATION

TEngo que crear dos secrets,el segundo es la private key de stripe.Habrá que asegurarse antes de a qué context apunto!

El primero puedo reasignarle el valor,el segundo es la secret key
# k create secret generic jwt-secret --from-literal=JWT_KEY=kubernetes
# k create secret generic stripe-secret --from-literal=STRIPE_KEY=...

Esto es algo que tengo que hacer en cada cluster que use esta aplicación.

				VIDEO 510 DON'T FORGET INGRESS-NGINX

DEbo recordar que tengo que crear un ingress en el cluster.Dependiendo del provider va a cambiar(AWS,DO,mikrok8s,minikube,...)

De momento tengo que usar el de DO:
https://kubernetes.github.io/ingress-nginx/deploy/#digital-ocean

TEngo que ver que crea el namespace,etc:

namespace/ingress-nginx created
serviceaccount/ingress-nginx created
configmap/ingress-nginx-controller created
clusterrole.rbac.authorization.k8s.io/ingress-nginx created

Y ahora debería poder ver algun pod,etc... aunque puede que tengan fallos.Lo arreglaremos en los siguientes videos.

				VIDEO 511 TESTING AUTOMATED DEPLOYMENT

Vamos a testear lo que hemos echo hasta ahora.Me cambio a dev y hago algun pequeño cambio,lo pusheo y desde Github hago una PR.Esto debería levantar los tests,recuerda,y cuando pasen acepto el merge.
Todo debería ir correcto.

				VIDEO 512 ADDITIONAL DEPLOY FILES





ACTUALIZACIONES.
1- La API version del Ingress Controller ha cambiado.Ahora pide el pathType y alguna cosa más.

apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: ingress-srv
  annotations:
    kubernetes.io/ingress.class: nginx
spec:
  rules:
    - host: posts.com
      http:
        paths:
          - path: /posts
            pathType: Prefix
            backend:
              service:
                name: posts-clusterip-srv
                port:
                  number: 4000

2- Desde node 15 las UnhandledPromises dan error y no un Warning.Puedo usar FROM: node16-alpine para usar la LTS de node16

3- Ha dejado los diagramas en un zip para poder verlos

4- Docker viene ahor con buildkit activado por defecto:
If you wish to disable the Buildkit feature so that you can more accurately follow along with the course, do the following:

Click the Docker Icon your systray
Select "Preferences"
Select "Docker Engine"
Change buildkit from true to false

{
  "features": {
    "buildkit": false
  },
  "experimental": false
}
Apply and Restart.


